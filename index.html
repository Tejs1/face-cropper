<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>
			Face-focused Photo Cropper (BlazeFace) with Synchronized Bounding Boxes
		</title>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@latest"></script>
		<style>
			body {
				font-family: Arial, sans-serif;
				max-width: 800px;
				margin: 0 auto;
				padding: 20px;
			}
			#fileInput {
				display: none;
			}
			#uploadButton {
				padding: 10px 20px;
				background-color: #4caf50;
				color: white;
				border: none;
				cursor: pointer;
			}
			#originalImageContainer,
			#croppedImage {
				max-width: 100%;
				margin-top: 20px;
			}
			#originalImageCanvas {
				max-width: 100%;
				height: auto;
			}
			#status {
				color: #666;
				margin-top: 10px;
			}
		</style>
	</head>
	<body>
		<h1>Face-focused Photo Cropper with Synchronized Bounding Boxes</h1>
		<input type="file" id="fileInput" accept="image/*" />
		<button id="uploadButton" disabled>Upload Photo</button>
		<div id="status">Loading face detection model...</div>
		<div id="originalImageContainer">
			<h2>Original Image with Bounding Boxes:</h2>
			<canvas id="originalImageCanvas"></canvas>
		</div>
		<div>
			<h2>Cropped Image:</h2>
			<img id="croppedImage" alt="Cropped image" />
		</div>

		<script>
			let model
			const TARGET_FACE_PERCENT = 0.8

			async function loadModel() {
				try {
					model = await blazeface.load()
					document.getElementById("status").textContent =
						"Face detection model loaded. Ready to process images."
					document.getElementById("uploadButton").disabled = false
				} catch (error) {
					console.error("Error loading BlazeFace model:", error)
					document.getElementById(
						"status",
					).textContent = `Error loading model: ${error.message}. Please reload the page.`
				}
			}

			async function detectFace(img) {
				const predictions = await model.estimateFaces(img, false)
				if (predictions.length > 0) {
					return predictions[0]
				}
				return null
			}

			function calculateCropArea(face, imgWidth, imgHeight) {
				const faceWidth = face.bottomRight[0] - face.topLeft[0]
				const faceHeight = face.bottomRight[1] - face.topLeft[1]
				const faceCenterX = (face.topLeft[0] + face.bottomRight[0]) / 2
				const faceCenterY = (face.topLeft[1] + face.bottomRight[1]) / 2

				const cropSize = Math.max(faceWidth, faceHeight) / TARGET_FACE_PERCENT

				let sourceX = faceCenterX - cropSize / 2
				let sourceY = faceCenterY - cropSize / 2

				// Adjust if crop area goes outside the image
				sourceX = Math.max(0, Math.min(sourceX, imgWidth - cropSize))
				sourceY = Math.max(0, Math.min(sourceY, imgHeight - cropSize))

				return { sourceX, sourceY, cropSize }
			}

			function drawBoundingBoxes(img, face, cropArea) {
				const canvas = document.getElementById("originalImageCanvas")
				const ctx = canvas.getContext("2d")

				canvas.width = img.width
				canvas.height = img.height

				ctx.drawImage(img, 0, 0, img.width, img.height)

				// Draw crop bounding box (green)
				ctx.strokeStyle = "green"
				ctx.lineWidth = 3
				ctx.strokeRect(
					cropArea.sourceX,
					cropArea.sourceY,
					cropArea.cropSize,
					cropArea.cropSize,
				)

				// Draw face bounding box (blue)
				const faceSize = cropArea.cropSize * TARGET_FACE_PERCENT
				const faceX = cropArea.sourceX + (cropArea.cropSize - faceSize) / 2
				const faceY = cropArea.sourceY + (cropArea.cropSize - faceSize) / 2

				ctx.strokeStyle = "blue"
				ctx.lineWidth = 3
				ctx.strokeRect(faceX, faceY, faceSize, faceSize)
			}

			function cropImage(img, cropArea) {
				const canvas = document.createElement("canvas")
				const ctx = canvas.getContext("2d")

				canvas.width = cropArea.cropSize
				canvas.height = cropArea.cropSize

				ctx.drawImage(
					img,
					cropArea.sourceX,
					cropArea.sourceY,
					cropArea.cropSize,
					cropArea.cropSize,
					0,
					0,
					cropArea.cropSize,
					cropArea.cropSize,
				)

				return canvas.toDataURL()
			}

			document.addEventListener("DOMContentLoaded", () => {
				const fileInput = document.getElementById("fileInput")
				const uploadButton = document.getElementById("uploadButton")
				const croppedImage = document.getElementById("croppedImage")
				const statusElement = document.getElementById("status")

				uploadButton.addEventListener("click", () => fileInput.click())

				loadModel()

				fileInput.addEventListener("change", async e => {
					const file = e.target.files[0]
					if (!file) return

					try {
						const img = new Image()
						img.onload = async () => {
							const face = await detectFace(img)
							if (face) {
								const cropArea = calculateCropArea(face, img.width, img.height)
								drawBoundingBoxes(img, face, cropArea)
								croppedImage.src = cropImage(img, cropArea)
								statusElement.textContent = "Image processed successfully."
							} else {
								statusElement.textContent = "No face detected in the image."
							}
						}
						img.src = URL.createObjectURL(file)
					} catch (error) {
						console.error("Error processing image:", error)
						statusElement.textContent = `Error processing image: ${error.message}. Please try again.`
					}
				})
			})
		</script>
	</body>
</html>
